import numpy as np
import pandas as pd
import os

from util import *


#데이터 부르기
import time
import yfinance as yf



#텐서플로
import tensorflow as tf



os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'


tm = time.localtime(time.time())
TODAY = f"{tm.tm_year}-{tm.tm_mon:0>2d}-{tm.tm_mday:0>2d}"

start_date='2012-03-01'
end_date="2022-05-01"
path = "./stock"


os.makedirs(path+"/asset",exist_ok=True)
ASSET = pd.read_csv('M6_Universe.csv')

for asset in ASSET.symbol:
    stock = yf.download(asset, start=start_date, end = end_date)
    stock.to_csv(path+"/asset/"+asset+".csv")


csvList=os.listdir(path+"/asset")

#include_list = []

for csv in csvList:
    if csv[-4:] != ".csv":
        continue
    
    data=pd.read_csv(path+"/asset"+'/'+csv)
    if(len(data)>2000):
        data=data[-2000-1:-1]
        data=data.reset_index()
        data=data[['Date','Adj Close']]
        data.columns = ['Date',csv[:-4]]
        
        #include_list.append(csv[:-4])
        
        if csv == csvList[0]:
            dataframe = data
        else:
            dataframe = pd.merge(dataframe,data,how="outer",on="Date")



dataframe["Date"] = pd.to_datetime(dataframe["Date"])
dataframe.sort_values(by=['Date'],inplace=True)
dataframe.fillna(method='ffill',inplace=True)
dataframe.fillna(method='bfill',inplace=True)
sort_asset = dataframe.columns.to_list()[1:]
sort_asset.sort()
sort_col = ["Date"]
sort_col.extend(sort_asset)
dataframe = dataframe[sort_col]

print(f'period : {dataframe["Date"].iloc[0]} ~ {dataframe["Date"].iloc[-1]}')
dataT=dataframe.drop(columns = "Date").copy()


dataframe


INDEX_DATA = make_index_data(start_date, end_date)


INDEX_DATA


ABBV = pd.read_csv("./stock/asset/ABBV.csv")
GOOG = pd.read_csv("./stock/asset/GOOG.csv")
SEGA_L = pd.read_csv("./stock/asset/SEGA.L.csv")


ABBV


class customLSTMcell(tf.keras.layers.LSTMCell):
    def __init__(self,
                 units,
                 activation='tanh',
                 recurrent_activation='sigmoid',
                 use_bias=True,
                 kernel_initializer='glorot_uniform',
                 recurrent_initializer='orthogonal',
                 bias_initializer='zeros',
                 unit_forget_bias=True,
                 kernel_regularizer=None,
                 recurrent_regularizer=None,
                 bias_regularizer=None,
                 kernel_constraint=None,
                 recurrent_constraint=None,
                 bias_constraint=None,
                 dropout=0.0,
                 recurrent_dropout=0.0,
                 **kwargs):
        super(customLSTMcell,self).__init__(units,
                                            activation,
                                            recurrent_activation,
                                            use_bias,
                                            kernel_initializer,
                                            recurrent_initializer,
                                            bias_initializer,
                                            unit_forget_bias,
                                            kernel_regularizer,
                                            recurrent_regularizer,
                                            bias_regularizer,
                                            kernel_constraint,
                                            recurrent_constraint,
                                            bias_constraint,
                                            dropout,
                                            recurrent_dropout,
                                            **kwargs)
        #추가 작업
        
    def call(self, inputs, states, training=None):
        h_tm1 = states[0]  # previous memory state
        c_tm1 = states[1]  # previous carry state

        dp_mask = self.get_dropout_mask_for_cell(inputs, training, count=4)
        rec_dp_mask = self.get_recurrent_dropout_mask_for_cell(h_tm1, training, count=4)

        if self.implementation == 1:
            if 0 < self.dropout < 1.:
                inputs_i = inputs * dp_mask[0]
                inputs_f = inputs * dp_mask[1]
                inputs_c = inputs * dp_mask[2]
                inputs_o = inputs * dp_mask[3]
            else:
                inputs_i = inputs
                inputs_f = inputs
                inputs_c = inputs
                inputs_o = inputs
            k_i, k_f, k_c, k_o = tf.split(self.kernel, num_or_size_splits=4, axis=1)
            x_i = backend.dot(inputs_i, k_i)
            x_f = backend.dot(inputs_f, k_f)
            x_c = backend.dot(inputs_c, k_c)
            x_o = backend.dot(inputs_o, k_o)
            if self.use_bias:
                b_i, b_f, b_c, b_o = tf.split(self.bias, num_or_size_splits=4, axis=0)
                x_i = backend.bias_add(x_i, b_i)
                x_f = backend.bias_add(x_f, b_f)
                x_c = backend.bias_add(x_c, b_c)
                x_o = backend.bias_add(x_o, b_o)

            if 0 < self.recurrent_dropout < 1.:
                h_tm1_i = h_tm1 * rec_dp_mask[0]
                h_tm1_f = h_tm1 * rec_dp_mask[1]
                h_tm1_c = h_tm1 * rec_dp_mask[2]
                h_tm1_o = h_tm1 * rec_dp_mask[3]
            else:
                h_tm1_i = h_tm1
                h_tm1_f = h_tm1
                h_tm1_c = h_tm1
                h_tm1_o = h_tm1
            x = (x_i, x_f, x_c, x_o)
            h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)
            c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)
        else:
            if 0. < self.dropout < 1.:
                inputs = inputs * dp_mask[0]
            z = backend.dot(inputs, self.kernel)
            z += backend.dot(h_tm1, self.recurrent_kernel)
            if self.use_bias:
                z = backend.bias_add(z, self.bias)

            z = tf.split(z, num_or_size_splits=4, axis=1)
            c, o = self._compute_carry_and_output_fused(z, c_tm1)

        h = o * self.activation(c)
        return h, [h, c]






