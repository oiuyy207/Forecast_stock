{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn=tf.compat.v1.nn.rnn_cell\n",
    "\n",
    "class base_LSTMCell(rnn.BasicLSTMCell):\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            concat = tf.layers.dense(tf.concat([inputs, h],axis=1), 4 * self._num_units)\n",
    "\n",
    "            # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "            i, j, f, o = tf.split(concat, 4, 1)\n",
    "\n",
    "            new_c = (c * tf.sigmoid(f + self._forget_bias) + tf.sigmoid(i) *\n",
    "                    self._activation(j))\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(o)\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n",
    "class MI_LSTMCell(rnn.BasicLSTMCell):\n",
    "    \"\"\"\n",
    "    Multi-Input LSTM proposed in the paper, Stock Price Prediction Using Attention-based Multi-Input LSTM.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "               num_units,\n",
    "               num_inputs,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the basic LSTM cell.\n",
    "        args:\n",
    "            num_inputs: MI-LSTM의 입력의 개수. \n",
    "                이 파라미터에 따라 입력 게이트의 어텐션 레이어를 설정.\n",
    "                최소 1개이상.\n",
    "                1개일 경우, 어텐션 레이어를 제외하고 기본 LSTM과 동일.\n",
    "        \"\"\"        \n",
    "        super(MI_LSTMCell,self).__init__(num_units,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs)\n",
    "        \n",
    "        if(type(num_inputs) is not int):\n",
    "            raise ValueError(\"num_inputs should be integer\")\n",
    "        if(num_inputs < 1):\n",
    "            raise ValueError(\"num_inputs should not be less than 0\")\n",
    "        self.num_inputs = num_inputs\n",
    "        self.alpha_weight=self.add_variable('alpha_weight',shape=[self._num_units,self._num_units])\n",
    "        self.alpha_bias=[]\n",
    "        for i in range(self.num_inputs):\n",
    "            self.alpha_bias.append(self.add_variable('alpha_bias'+str(i),shape=[1],initializer=tf.zeros_initializer()))\n",
    "\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.compat.v1.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            inputs_list = tf.split(inputs,self.num_inputs,1)\n",
    "            concat = tf.compat.v1.layers.dense(tf.concat([inputs_list[0], h],axis=1), (3+self.num_inputs) * self._num_units)\n",
    "                                 \n",
    "            # 0 = forget_gate, 1 = output_gate, 2= main_new_input, 3 = main_input_gate, 4~ = input_gate_for_auxiliary\n",
    "            main_list = tf.split(concat, 3+self.num_inputs, 1)\n",
    "                        \n",
    "            #new_input_gate= list of all new_input.\n",
    "            new_input_gate=[tf.tanh(main_list[2])]\n",
    "            #linear layer for auxiliary inputs.\n",
    "            for i in range(1,self.num_inputs):\n",
    "                new_input_gate.append(tf.compat.v1.layers.dense(tf.concat([inputs_list[i], h],axis=1),self._num_units,activation=tf.tanh))\n",
    "\n",
    "            #making list of l. l = sigmoid(input_gate) * tanh(new_input)\n",
    "            new_l=[]\n",
    "            for i,new_input in enumerate(new_input_gate,3):\n",
    "                new_l.append(tf.sigmoid(main_list[i]) * new_input)\n",
    "\n",
    "\n",
    "            #making list of u.            \n",
    "            u=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                #temp = transpos(l) X W X Cell_State.\n",
    "                temp1=tf.matmul(l,self.alpha_weight)\n",
    "                temp1=tf.expand_dims(temp1,1)\n",
    "                temp2=tf.matmul(temp1,tf.expand_dims(c,2))\n",
    "                u.append(tf.tanh(tf.squeeze(temp2+self.alpha_bias[i],axis=2)))\n",
    "\n",
    "            #making list of alpha.\n",
    "            alpha=tf.nn.softmax(u,axis=0)\n",
    "\n",
    "            #making L.\n",
    "            L=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                L.append(alpha[i]*l)\n",
    "            L=tf.reduce_sum(L,axis=0)\n",
    "\n",
    "\n",
    "            #new state = c(t-1) * f + L. new h = tanh(c) + sigmoid(o)\n",
    "            new_c = (c * tf.sigmoid(main_list[0] + self._forget_bias)+L)\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(main_list[1])\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n",
    "\n",
    "class Attention_Layer():\n",
    "    \"\"\"\n",
    "    어텐션 레이어.\n",
    "    (None, TimeWindow, hidden_unit_size) shape의 LSTM 출력을 입력으로 받아 (None, 1, hidden_unit_size)의 텐서 출력.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        timewindow_size,\n",
    "        input_hidden_unit_size,\n",
    "        attention_size=None):\n",
    "        \"\"\"\n",
    "        Setting parameter for attention layer.\n",
    "        args:\n",
    "            timewindow_size = time window size of previous lstm layer.\n",
    "            input_hidden_unit_size = hidden unit number of previous lstm layer.\n",
    "            attention_size = size of this attention. \n",
    "                default = input_hidden_unit_size.\n",
    "        \"\"\"\n",
    "        if(attention_size is None):\n",
    "            attention_size=input_hidden_unit_size\n",
    "        self.o_size=attention_size\n",
    "        self.h_size=input_hidden_unit_size\n",
    "        self.t_size=timewindow_size\n",
    "\n",
    "        self.beta_weight=tf.Variable(tf.random.normal([self.h_size,self.o_size]), name='beta_weight')\n",
    "        self.beta_bias=tf.Variable(tf.zeros([self.o_size]),name='beta_bias')\n",
    "\n",
    "        self.v=tf.Variable(tf.random.normal([self.o_size,1]),name='beta_v')\n",
    "\n",
    "    def __call__(self,inputs):\n",
    "        \"\"\"\n",
    "        producing output with actual inputs.\n",
    "        shape of output will be (batch_size, 1, input_hidden_unit_size).\n",
    "        \"\"\"\n",
    "        #temp = tanh(Y X W + b) ->shape of result = (-1, self.o_size)\n",
    "        temp=tf.matmul(tf.reshape(inputs,[-1,self.h_size]),self.beta_weight)\n",
    "         \n",
    "        temp=tf.tanh(temp+self.beta_bias)\n",
    "        \n",
    "            \n",
    "        #j=temp X v\n",
    "        j=tf.reshape(tf.matmul(temp,self.v),[-1,self.t_size,1])\n",
    "\n",
    "        beta=tf.nn.softmax(j)\n",
    "        \n",
    "        \n",
    "\n",
    "        output=beta*inputs\n",
    "        return output\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M6_LJY",
   "language": "python",
   "name": "m6_ljy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
